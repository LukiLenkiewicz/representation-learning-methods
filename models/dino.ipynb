{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import STL10\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "unlabeled_dataset = STL10(root='../data', split='unlabeled', download=True, transform=transform)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "def get_resnet_backbone():\n",
    "    model = resnet18(pretrained=True)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = torch.nn.Identity()\n",
    "    return model, in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adam\\miniconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adam\\miniconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DINOHead(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, use_bn=False):\n",
    "        super(DINOHead, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, 2048),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(2048, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class DINOLoss(nn.Module):\n",
    "    def __init__(self, out_dim):\n",
    "        super(DINOLoss, self).__init__()\n",
    "        self.register_buffer(\"center\", torch.zeros(1, out_dim))\n",
    "        self.teacher_temp = 0.04\n",
    "        self.student_temp = 0.1\n",
    "        self.center_momentum = 0.9\n",
    "\n",
    "    def forward(self, student_output, teacher_output):\n",
    "        teacher_output = F.softmax((teacher_output - self.center) / self.teacher_temp, dim=-1).detach()\n",
    "        student_output = F.log_softmax(student_output / self.student_temp, dim=-1)\n",
    "\n",
    "        loss = torch.mean(torch.sum(-teacher_output * student_output, dim=-1))\n",
    "\n",
    "        self.update_center(teacher_output)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_center(self, teacher_output):\n",
    "        batch_center = torch.mean(teacher_output, dim=0, keepdim=True)\n",
    "        self.center = self.center * self.center_momentum + batch_center * (1 - self.center_momentum)\n",
    "\n",
    "class DINO(nn.Module):\n",
    "    def __init__(self, backbone, head):\n",
    "        super(DINO, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.head = head\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.head(features)\n",
    "\n",
    "backbone, in_feat = get_resnet_backbone()\n",
    "student_head = DINOHead(in_dim=in_feat, out_dim=65536)\n",
    "teacher_head = DINOHead(in_dim=in_feat, out_dim=65536)\n",
    "\n",
    "student = DINO(backbone, student_head)\n",
    "teacher = DINO(backbone, teacher_head)\n",
    "\n",
    "for param in teacher.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "criterion = DINOLoss(out_dim=65536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6caea0475049b88c334a4e7f0ff961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [1/5]:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 6.1964\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331c176a0c144532bd76016a1cfe42fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [2/5]:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 5.8126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f2b9a2efb44d3083dbd90b4bb98d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [3/5]:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 5.4330\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4a9b44c141456e96b8159b6097bf64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [4/5]:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 6.1183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30526fd82bc6408caf3335795b7f4ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [5/5]:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 5.4700\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "student = student.to(device)\n",
    "teacher = teacher.to(device)\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.Adam(student.parameters(), lr=0.001)\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, _ in tqdm(unlabeled_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False):\n",
    "        images = images.to(device)\n",
    "\n",
    "        student_output = student(images)\n",
    "        with torch.no_grad():\n",
    "            teacher_output = teacher(images)\n",
    "\n",
    "        loss = criterion(student_output, teacher_output)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
