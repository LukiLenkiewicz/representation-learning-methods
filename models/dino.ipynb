{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models as torchvision_models\n",
    "\n",
    "from utils import *\n",
    "import vision_transformer as vits\n",
    "from vision_transformer import DINOHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dino(args):\n",
    "    init_distributed_mode(args)\n",
    "    fix_random_seeds(args.seed)\n",
    "\n",
    "    transform = DataAugmentationDINO(\n",
    "        args.global_crops_scale,\n",
    "        args.local_crops_scale,\n",
    "        args.local_crops_number,\n",
    "    )\n",
    "    dataset = datasets.ImageFolder(args.data_path, transform=transform)\n",
    "    sampler = torch.data.DistributedSampler(dataset, shuffle=True)\n",
    "    data_loader = torch.data.DataLoader(\n",
    "        dataset,\n",
    "        sampler=sampler,\n",
    "        batch_size=args.batch_size_per_gpu,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    args.arch = args.arch.replace(\"deit\", \"vit\")\n",
    "\n",
    "    if args.arch in vits.__dict__.keys():\n",
    "        student = vits.__dict__[args.arch](\n",
    "            patch_size=args.patch_size,\n",
    "            drop_path_rate=args.drop_path_rate,  # stochastic depth\n",
    "        )\n",
    "        teacher = vits.__dict__[args.arch](patch_size=args.patch_size)\n",
    "        embed_dim = student.embed_dim\n",
    "    # if the network is a XCiT\n",
    "    elif args.arch in torch.hub.list(\"facebookresearch/xcit:main\"):\n",
    "        student = torch.hub.load('facebookresearch/xcit:main', args.arch,\n",
    "                                 pretrained=False, drop_path_rate=args.drop_path_rate)\n",
    "        teacher = torch.hub.load('facebookresearch/xcit:main', args.arch, pretrained=False)\n",
    "        embed_dim = student.embed_dim\n",
    "    # otherwise, we check if the architecture is in torchvision models\n",
    "    elif args.arch in torchvision_models.__dict__.keys():\n",
    "        student = torchvision_models.__dict__[args.arch]()\n",
    "        teacher = torchvision_models.__dict__[args.arch]()\n",
    "        embed_dim = student.fc.weight.shape[1]\n",
    "    else:\n",
    "        print(f\"Unknow architecture: {args.arch}\")\n",
    "\n",
    "    # multi-crop wrapper handles forward with inputs of different resolutions\n",
    "    student = MultiCropWrapper(student, DINOHead(\n",
    "        embed_dim,\n",
    "        args.out_dim,\n",
    "        use_bn=args.use_bn_in_head,\n",
    "        norm_last_layer=args.norm_last_layer,\n",
    "    ))\n",
    "    teacher = MultiCropWrapper(\n",
    "        teacher,\n",
    "        DINOHead(embed_dim, args.out_dim, args.use_bn_in_head),\n",
    "    )\n",
    "    # move networks to gpu\n",
    "    student, teacher = student.cuda(), teacher.cuda()\n",
    "    # synchronize batch norms (if any)\n",
    "    if has_batchnorms(student):\n",
    "        student = nn.SyncBatchNorm.convert_sync_batchnorm(student)\n",
    "        teacher = nn.SyncBatchNorm.convert_sync_batchnorm(teacher)\n",
    "\n",
    "        # we need DDP wrapper to have synchro batch norms working...\n",
    "        teacher = nn.parallel.DistributedDataParallel(teacher, device_ids=[args.gpu])\n",
    "        teacher_without_ddp = teacher.module\n",
    "    else:\n",
    "        # teacher_without_ddp and teacher are the same thing\n",
    "        teacher_without_ddp = teacher\n",
    "    student = nn.parallel.DistributedDataParallel(student, device_ids=[args.gpu])\n",
    "    # teacher and student start with the same weights\n",
    "    teacher_without_ddp.load_state_dict(student.module.state_dict())\n",
    "    # there is no backpropagation through the teacher, so no need for gradients\n",
    "    for p in teacher.parameters():\n",
    "        p.requires_grad = False\n",
    "    print(f\"Student and Teacher are built: they are both {args.arch} network.\")\n",
    "\n",
    "    # ============ preparing loss ... ============\n",
    "    dino_loss = DINOLoss(\n",
    "        args.out_dim,\n",
    "        args.local_crops_number + 2,  # total number of crops = 2 global crops + local_crops_number\n",
    "        args.warmup_teacher_temp,\n",
    "        args.teacher_temp,\n",
    "        args.warmup_teacher_temp_epochs,\n",
    "        args.epochs,\n",
    "    ).cuda()\n",
    "\n",
    "    # ============ preparing optimizer ... ============\n",
    "    params_groups = get_params_groups(student)\n",
    "    if args.optimizer == \"adamw\":\n",
    "        optimizer = torch.optim.AdamW(params_groups)  # to use with ViTs\n",
    "    elif args.optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(params_groups, lr=0, momentum=0.9)  # lr is set by scheduler\n",
    "    elif args.optimizer == \"lars\":\n",
    "        optimizer = LARS(params_groups)  # to use with convnet and large batches\n",
    "    # for mixed precision training\n",
    "    fp16_scaler = None\n",
    "    if args.use_fp16:\n",
    "        fp16_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # ============ init schedulers ... ============\n",
    "    lr_schedule = cosine_scheduler(\n",
    "        args.lr * (args.batch_size_per_gpu * get_world_size()) / 256.,  # linear scaling rule\n",
    "        args.min_lr,\n",
    "        args.epochs, len(data_loader),\n",
    "        warmup_epochs=args.warmup_epochs,\n",
    "    )\n",
    "    wd_schedule = cosine_scheduler(\n",
    "        args.weight_decay,\n",
    "        args.weight_decay_end,\n",
    "        args.epochs, len(data_loader),\n",
    "    )\n",
    "    # momentum parameter is increased to 1. during training with a cosine schedule\n",
    "    momentum_schedule = cosine_scheduler(args.momentum_teacher, 1,\n",
    "                                               args.epochs, len(data_loader))\n",
    "    print(f\"Loss, optimizer and schedulers ready.\")\n",
    "\n",
    "    # ============ optionally resume training ... ============\n",
    "    to_restore = {\"epoch\": 0}\n",
    "    restart_from_checkpoint(\n",
    "        os.path.join(args.output_dir, \"checkpoint.pth\"),\n",
    "        run_variables=to_restore,\n",
    "        student=student,\n",
    "        teacher=teacher,\n",
    "        optimizer=optimizer,\n",
    "        fp16_scaler=fp16_scaler,\n",
    "        dino_loss=dino_loss,\n",
    "    )\n",
    "    start_epoch = to_restore[\"epoch\"]\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Starting DINO training !\")\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        data_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        # ============ training one epoch of DINO ... ============\n",
    "        train_stats = train_one_epoch(student, teacher, teacher_without_ddp, dino_loss,\n",
    "            data_loader, optimizer, lr_schedule, wd_schedule, momentum_schedule,\n",
    "            epoch, fp16_scaler, args)\n",
    "\n",
    "        # ============ writing logs ... ============\n",
    "        save_dict = {\n",
    "            'student': student.state_dict(),\n",
    "            'teacher': teacher.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch + 1,\n",
    "            'args': args,\n",
    "            'dino_loss': dino_loss.state_dict(),\n",
    "        }\n",
    "        if fp16_scaler is not None:\n",
    "            save_dict['fp16_scaler'] = fp16_scaler.state_dict()\n",
    "        save_on_master(save_dict, os.path.join(args.output_dir, 'checkpoint.pth'))\n",
    "        if args.saveckp_freq and epoch % args.saveckp_freq == 0:\n",
    "            save_on_master(save_dict, os.path.join(args.output_dir, f'checkpoint{epoch:04}.pth'))\n",
    "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "                     'epoch': epoch}\n",
    "        if is_main_process():\n",
    "            with (Path(args.output_dir) / \"log.txt\").open(\"a\") as f:\n",
    "                f.write(json.dumps(log_stats) + \"\\n\")\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))\n",
    "\n",
    "\n",
    "def train_one_epoch(student, teacher, teacher_without_ddp, dino_loss, data_loader,\n",
    "                    optimizer, lr_schedule, wd_schedule, momentum_schedule,epoch,\n",
    "                    fp16_scaler, args):\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    header = 'Epoch: [{}/{}]'.format(epoch, args.epochs)\n",
    "    for it, (images, _) in enumerate(metric_logger.log_every(data_loader, 10, header)):\n",
    "        # update weight decay and learning rate according to their schedule\n",
    "        it = len(data_loader) * epoch + it  # global training iteration\n",
    "        for i, param_group in enumerate(optimizer.param_groups):\n",
    "            param_group[\"lr\"] = lr_schedule[it]\n",
    "            if i == 0:  # only the first group is regularized\n",
    "                param_group[\"weight_decay\"] = wd_schedule[it]\n",
    "\n",
    "        # move images to gpu\n",
    "        images = [im.cuda(non_blocking=True) for im in images]\n",
    "        # teacher and student forward passes + compute dino loss\n",
    "        with torch.cuda.amp.autocast(fp16_scaler is not None):\n",
    "            teacher_output = teacher(images[:2])  # only the 2 global views pass through the teacher\n",
    "            student_output = student(images)\n",
    "            loss = dino_loss(student_output, teacher_output, epoch)\n",
    "\n",
    "        if not math.isfinite(loss.item()):\n",
    "            print(\"Loss is {}, stopping training\".format(loss.item()), force=True)\n",
    "            sys.exit(1)\n",
    "\n",
    "        # student update\n",
    "        optimizer.zero_grad()\n",
    "        param_norms = None\n",
    "        if fp16_scaler is None:\n",
    "            loss.backward()\n",
    "            if args.clip_grad:\n",
    "                param_norms = clip_gradients(student, args.clip_grad)\n",
    "            cancel_gradients_last_layer(epoch, student,\n",
    "                                              args.freeze_last_layer)\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            fp16_scaler.scale(loss).backward()\n",
    "            if args.clip_grad:\n",
    "                fp16_scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params in-place\n",
    "                param_norms = clip_gradients(student, args.clip_grad)\n",
    "            cancel_gradients_last_layer(epoch, student,\n",
    "                                              args.freeze_last_layer)\n",
    "            fp16_scaler.step(optimizer)\n",
    "            fp16_scaler.update()\n",
    "\n",
    "        # EMA update for the teacher\n",
    "        with torch.no_grad():\n",
    "            m = momentum_schedule[it]  # momentum parameter\n",
    "            for param_q, param_k in zip(student.module.parameters(), teacher_without_ddp.parameters()):\n",
    "                param_k.data.mul_(m).add_((1 - m) * param_q.detach().data)\n",
    "\n",
    "        # logging\n",
    "        torch.cuda.synchronize()\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "        metric_logger.update(wd=optimizer.param_groups[0][\"weight_decay\"])\n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print(\"Averaged stats:\", metric_logger)\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
    "\n",
    "\n",
    "class DINOLoss(nn.Module):\n",
    "    def __init__(self, out_dim, ncrops, warmup_teacher_temp, teacher_temp,\n",
    "                 warmup_teacher_temp_epochs, nepochs, student_temp=0.1,\n",
    "                 center_momentum=0.9):\n",
    "        super().__init__()\n",
    "        self.student_temp = student_temp\n",
    "        self.center_momentum = center_momentum\n",
    "        self.ncrops = ncrops\n",
    "        self.register_buffer(\"center\", torch.zeros(1, out_dim))\n",
    "        # we apply a warm up for the teacher temperature because\n",
    "        # a too high temperature makes the training instable at the beginning\n",
    "        self.teacher_temp_schedule = np.concatenate((\n",
    "            np.linspace(warmup_teacher_temp,\n",
    "                        teacher_temp, warmup_teacher_temp_epochs),\n",
    "            np.ones(nepochs - warmup_teacher_temp_epochs) * teacher_temp\n",
    "        ))\n",
    "\n",
    "    def forward(self, student_output, teacher_output, epoch):\n",
    "        \"\"\"\n",
    "        Cross-entropy between softmax outputs of the teacher and student networks.\n",
    "        \"\"\"\n",
    "        student_out = student_output / self.student_temp\n",
    "        student_out = student_out.chunk(self.ncrops)\n",
    "\n",
    "        # teacher centering and sharpening\n",
    "        temp = self.teacher_temp_schedule[epoch]\n",
    "        teacher_out = F.softmax((teacher_output - self.center) / temp, dim=-1)\n",
    "        teacher_out = teacher_out.detach().chunk(2)\n",
    "\n",
    "        total_loss = 0\n",
    "        n_loss_terms = 0\n",
    "        for iq, q in enumerate(teacher_out):\n",
    "            for v in range(len(student_out)):\n",
    "                if v == iq:\n",
    "                    # we skip cases where student and teacher operate on the same view\n",
    "                    continue\n",
    "                loss = torch.sum(-q * F.log_softmax(student_out[v], dim=-1), dim=-1)\n",
    "                total_loss += loss.mean()\n",
    "                n_loss_terms += 1\n",
    "        total_loss /= n_loss_terms\n",
    "        self.update_center(teacher_output)\n",
    "        return total_loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_center(self, teacher_output):\n",
    "        \"\"\"\n",
    "        Update center used for teacher output.\n",
    "        \"\"\"\n",
    "        batch_center = torch.sum(teacher_output, dim=0, keepdim=True)\n",
    "        dist.all_reduce(batch_center)\n",
    "        batch_center = batch_center / (len(teacher_output) * dist.get_world_size())\n",
    "\n",
    "        # ema update\n",
    "        self.center = self.center * self.center_momentum + batch_center * (1 - self.center_momentum)\n",
    "\n",
    "\n",
    "class DataAugmentationDINO(object):\n",
    "    def __init__(self, global_crops_scale, local_crops_scale, local_crops_number):\n",
    "        flip_and_color_jitter = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply(\n",
    "                [transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)],\n",
    "                p=0.8\n",
    "            ),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "        ])\n",
    "        normalize = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "\n",
    "        # first global crop\n",
    "        self.global_transfo1 = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, scale=global_crops_scale, interpolation=Image.BICUBIC),\n",
    "            flip_and_color_jitter,\n",
    "            GaussianBlur(1.0),\n",
    "            normalize,\n",
    "        ])\n",
    "        # second global crop\n",
    "        self.global_transfo2 = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, scale=global_crops_scale, interpolation=Image.BICUBIC),\n",
    "            flip_and_color_jitter,\n",
    "            GaussianBlur(0.1),\n",
    "            Solarization(0.2),\n",
    "            normalize,\n",
    "        ])\n",
    "        # transformation for the local small crops\n",
    "        self.local_crops_number = local_crops_number\n",
    "        self.local_transfo = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(96, scale=local_crops_scale, interpolation=Image.BICUBIC),\n",
    "            flip_and_color_jitter,\n",
    "            GaussianBlur(p=0.5),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        crops = []\n",
    "        crops.append(self.global_transfo1(image))\n",
    "        crops.append(self.global_transfo2(image))\n",
    "        for _ in range(self.local_crops_number):\n",
    "            crops.append(self.local_transfo(image))\n",
    "        return crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does not support training without GPU.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xadamo/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "train_dino(\n",
    "    args = {\n",
    "        \"data_path\": \"..data/unlabeled\",\n",
    "        \"output_dir\": \"../dino\",\n",
    "        \"arch\": \"vit_base_patch16_224\",\n",
    "        \"patch_size\": 16,\n",
    "        \"out_dim\": 65536,\n",
    "        \"local_crops_scale\": (0.08, 0.32),\n",
    "        \"local_crops_number\": 8,\n",
    "        \"global_crops_scale\": (0.4, 1.0),\n",
    "        \"batch_size_per_gpu\": 64,\n",
    "        \"epochs\": 300,\n",
    "        \"freeze_last_layer\": 1,\n",
    "        \"warmup_teacher_temp\": 0.04,\n",
    "        \"teacher_temp\": 0.04,\n",
    "        \"warmup_teacher_temp_epochs\": 0,\n",
    "        \"lr\": 0.0005,\n",
    "        \"min_lr\": 0.0001,\n",
    "        \"weight_decay\": 0.04,\n",
    "        \"weight_decay_end\": 0.4,\n",
    "        \"momentum_teacher\": 0.996,\n",
    "        \"warmup_epochs\": 0,\n",
    "        \"optimizer\": \"adamw\",\n",
    "        \"clip_grad\": 3.0,\n",
    "        \"use_fp16\": True,\n",
    "        \"use_bn_in_head\": False,\n",
    "        \"norm_last_layer\": True,\n",
    "        \"drop_path_rate\": 0.1,\n",
    "        \"seed\": 0,\n",
    "        \"gpu\": 0,\n",
    "        \"num_workers\": 10,\n",
    "        \"saveckp_freq\": 10,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
