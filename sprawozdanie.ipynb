{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie reprezentacji 2024 - sprawozdanie\n",
    "\n",
    "### Grupa:\n",
    "- Łukasz Lenkiewicz\n",
    "- Jan Masłowski\n",
    "- Adam Bednarski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opis problemu:\n",
    "## Opis zadania\n",
    "Celem projektu jest porównanie skuteczności kilku wybranych modeli w zadaniu uczenia samonadzorownego. Uczenie samonadzorowane jest paradygmatem uczenia maszynowego pozwalającym na wykorzystanie niezaetykietowanych danych no wyekstrahowania wiedzy, która może potem zostać użyta do innego zadania uczenia maszynowego. W ramach realizacji projektu wytrenowane przy pomocy uczenia samonadzorowanego modele zostaną użyte w zadaniu klasyfikacji obrazu. W\n",
    "\n",
    "Modele wykorzystujące pretrenowane enkodery powinny w teorii uzyskać lepsze wyniki niż modele uczone \"od zera\" z losowo zainicjowanymi wagami.\n",
    "\n",
    "## Opis Zbioru Danych\n",
    "STL-10 jest zbiorem danych przeznaczonym głównie do zadań uczenia maszynowego bez nadzoru oraz transferu uczenia. Zbiór ten zawiera obrazy w formacie RGB w niskiej rozdzielczości (96x96 pikseli) należące do 10 różnych klas. Każda klasa reprezentuje inną kategorię obiektów.\n",
    "\n",
    "Zbiór danych STL-10 składa się z następujących części:\n",
    "- Zbiór treningowy: 5000 obrazów, po 500 dla każdej klasy.\n",
    "- Zbiór testowy: 8000 obrazów, po 800 dla każdej klasy.\n",
    "- Zbiór niezaetykietowany: 100000 obrazów, które nie są przypisane do\n",
    "żadnej klasy.\n",
    "\n",
    "Zbiór danych STL-10 obejmuje następujące klasy obiektów:\n",
    "- Samolot\n",
    "- Ptak\n",
    "- Samochód\n",
    "- Kot\n",
    "- Jeleń\n",
    "- Pies\n",
    "- Koń\n",
    "- Małpa\n",
    "- Statek\n",
    "- Ciężarówka\n",
    "\n",
    "Przykładowe próbki dla danych klas:\n",
    "\n",
    "![obrazki](imgs/imglabel.png)\n",
    "\n",
    "Zbiór treningowy STL-10 jest zbalansowany, co oznacza, że każda z klas zawiera taką samą liczbę obrazów. Poniżej przedstawiamy rozkład liczby obrazów w zbiorze treningowym i testowym: \n",
    "\n",
    "| Klasa      | Liczba obrazów (trening) | Liczba obrazów (test) |\n",
    "|------------|--------------------------|-----------------------|\n",
    "| Pies       | 500                      | 800                   |\n",
    "| Kot        | 500                      | 800                   |\n",
    "| Koń        | 500                      | 800                   |\n",
    "| Ptak       | 500                      | 800                   |\n",
    "| Samochód   | 500                      | 800                   |\n",
    "| Ciężarówka | 500                      | 800                   |\n",
    "| Samolot    | 500                      | 800                   |\n",
    "| Małpa      | 500                      | 800                   |\n",
    "| Statek     | 500                      | 800                   |\n",
    "| Jeleń      | 500                      | 800                   |\n",
    "| **Razem**  | **5000**                 | **8000**              |\n",
    "\n",
    "Średnie i Odchylenie Standardowe Wartości Pikseli\n",
    "\n",
    "| Klasa      | Liczba obrazów (trening) | Liczba obrazów (test) |\n",
    "|------------|--------------------------|-----------------------|\n",
    "|     R      |         0.4467           |       0.2603          |\n",
    "|     G      |         0.4398           |       0.2566          |\n",
    "|     B      |         0.4066           |       0.2713          |\n",
    "\n",
    "Zbiór danych STL-10 jest zbalansowany, a dane niezaetykietowane stanowią jego znaczną część. Czyni go to idealnym do zadań uczenia samonadzorowanego. Analiza rozkładu liczby obrazów w klasach oraz statystyk pikseli wskazuje na jednolitość i spójność danych. Wizualizacja obrazów pokazuje, że obrazy w każdej klasie są zróżnicowane, co może stanowić wyzwanie dla modeli generatywnych, ale jednocześnie pozwala na lepsze ocenienie ich zdolności do uczenia reprezentacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Wybrane modele\n",
    "### Variational Autoencoder [^1]\n",
    "Wariacyjny Autoenkoder jest jednym z najpopularniejszych modeli generatywnych. Jak każdy model generatywny jego podstawowym zadaniem jego zadaniem\n",
    "jest nauczenie się rozkładu danych, w sposób umożliwiający generowanie realistycznych próbek z tego rozkładu.\n",
    "\n",
    "## Generative Latent Flow [^2]\n",
    "Modele typu Normalizing Flows to rodzaj modeli generatywnych, które umożli wiają dokładne modelowanie rozkładów prawdopodobieństwa poprzez sekwencję\n",
    "odwracalnych transformacji. W przeciwieństwie do modeli takich jak VAE, Flowy pozwalają na dokładne oszacowanie wartości funkcji wiarygodności. W standardowym wariancie, modele tego typu nie redukują wymiarowości, a więc uniemożliwiają tworzenie niskowymiarowych reprezentacji danych wejściowych. Sprawia to, że one są kosztowne obliczeniowo. Z tego powodu wykorzystany został model Generative Latent Flow, który estymuje wartość funkcji\n",
    "wiarygodności na podstawie reprezentacji ukrytej przykładu wejściowego.\n",
    "\n",
    "\n",
    "## Dino [^3]\n",
    "TBA...\n",
    "\n",
    "[^1]: VAE - Kingma, Diederik P., and Max Welling. \"Auto-encoding variational bayes.\" arXiv preprint arXiv:1312.6114 (2013).\n",
    "\n",
    "\n",
    "[^2]: Generative Latent Flow - Xiao, Zhisheng, Qing Yan, and Yali Amit. \"Generative latent flow.\" arXiv preprint arXiv:1905.10485 (2019).\n",
    "\n",
    "[^3]: DINO - Caron, Mathilde, et al. \"Emerging properties in self-supervised vision transformers.\" Proceedings of the IEEE/CVF international conference on computer vision. 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Opis eksperymentów\n",
    "## Przygotowanie zbioru danych\n",
    "### Podział na zbiory uczące i walidacyjne\n",
    "Zbiór STL-10 składa się z danych zaetykietowanych i niezaetykietowanych. 80% danych niezaetykietowanych posłużyło do zadania wstępnego, a pozostałe 20% do walidacji. W przypadku danych zaetykietowanych dla zbioru walidacyjnego zastosowany został analogiczny podział. Dodatkowo zawiera on osobny zbiór testowy, który posłużył do otrzymania ostatecznych wyników klasyfikacji.\n",
    "\n",
    "### Transformacje\n",
    "Obrazy zostały zapisane jako 3-wymiarowe tensory o wymiarach 3x96x96. Wartości poszczególnych pikseli mieszczą się w przedziale od 0 do 1. Ze względu na wcześniejsze doświadczenia z tym zbiorem danych (znormalizowane dane uzyskiwały z reguły gorsze wyniki) nie przeprowadzono żadnej normalizacji.\n",
    "\n",
    "### Augmentacje danych\n",
    "Liczne augmentacje danych są ważnym czynnikiem w modelu DINO. Z tego powodu jest ich dużo.\n",
    "TBA...\n",
    "\n",
    "W przypadku VAE oraz Latent Flowa nie zostały zastowane żadne augmentacje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Metryki\n",
    "\n",
    "## Rekonstrukcja\n",
    "W celu oceny jakości rekonstrukcji zastosowano następujące metryki:\n",
    "\n",
    "- Binarna entropia krzyżowa (ang. binary cross-entropy) jest często używana jako funkcja kosztu w zadaniach klasyfikacji binarnej. Jej ogólna postać to:\n",
    "$$\n",
    "\\text{BCE} = - \\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
    "$$\n",
    "gdzie:\n",
    "- N - liczba próbek,\n",
    "- $y_i$ - rzeczywista etykieta klasy dla próbki $i$ (0 lub 1),\n",
    "- $\\hat{y}_i$ - przewidywane prawdopodobieństwo przynależności próbki $i$ do klasy 1.\n",
    "Jeżeli używane są logity ($z$) jako surowe wyniki modelu przed zastosowaniem funkcji sigmoid, to przewidywane prawdopodobieństwo $\\hat{y}$ jest dane przez:\n",
    "$$\n",
    "\\hat{y} = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "gdzie $\\sigma(z)$ to funkcja sigmoid. Entropia krzyżowa może mieć wówczas następującą postać:\n",
    "$$\n",
    "BCE = \\frac{1}{N} \\sum_{i=1}^{N} \\left[ \\log\\left( 1 + e^{z_i} \\right) - y_i z_i \\right]\n",
    "$$\n",
    "gdzie $z_i$ to logity dla próbki $i$\n",
    "\n",
    "- Błąd średniokwadratowy - jedna z popularniejszy metod oceny rekonstrukcji danych wejściowych polega na odjęciu danych rzeczywistych od danych zwróconych przez model\n",
    "$$\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\hat{x}_i)^2$$\n",
    "gdzie $x_i$ to rzeczywista próbka danych, a $\\hat{x}_i$ to jego rekonstrukcja.\n",
    "\n",
    "\n",
    "## Klasyfikacja\n",
    "W ocenie jakości klasyfikacji kierowano się trzema metrykami:\n",
    "\n",
    "- Entropią krzyżową, różnicą między rzeczywistym rozkładem danych, a zwracanym przez model:\n",
    "    $$\\mathcal{L} = -\\frac{1}{n} \\sum_{i=1}^n \\sum_{c=1}^C y_{i,c} \\log(\\hat{p}_{i,c})$$\n",
    "    Gdzie $y_{i, c}$ inormacja czy przykład $i$ ma etykietę c, a $\\hat{p}_{c, i}$ rozkład etykiet zwracany przez model.\n",
    "    \n",
    "- Dokładnością czyli sumą poprawnych predykcji podzieloną przez wartość wszystkich predykcji: \n",
    "$$\\text{Acc} = \\frac{\\sum_{i=1}^n \\mathbf{1}(\\hat{y}_i = y_i)}{n}$$\n",
    "- Miarą F1 wykorzystywaną w danych niezbalansowanych, ze względu na zbalansowane dane jest to metryka jedynie pomocnicza gdzie $y_i$ to rzeczywista etykieta danych, a $\\hat{y}_i$ to predykcja modelu. $$\\text{F1-score}  = \\frac{2 \\cdot \\text{TP}}{2\\cdot \\text{TP} + \\text{FP} + \\text{FN}}$$ gdzie $TP$ to przykłady poprawnie sklasyfikowane jako True, $FP$ to przykłady fałszywie sklasyfikowane jako True, a $FN$ przykłady fałszywie sklasyfikowane jako False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
